#!/usr/bin/env python3
"""
LLMã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿéš›ã®OpenAI APIã‚’ä½¿ç”¨ã—ã¦ãƒ­ã‚°æ©Ÿèƒ½ã‚’æ¤œè¨¼
"""
import os
import time
from pathlib import Path
from logger import LLMInteractionLogger
from src.llm_teacher import LLMTeacher
from src.tower_defense_environment import TowerDefenseEnvironment


def test_llm_interaction_logging():
    """LLMã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    
    # APIã‚­ãƒ¼ã®ç¢ºèª
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ OPENAI_API_KEY not set")
        return False
    
    print(f"âœ… OpenAI API Key configured: {api_key[:10]}...")
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    test_dir = Path("runs/real/llm_logging_test")
    test_dir.mkdir(parents=True, exist_ok=True)
    
    # ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
    llm_logger = LLMInteractionLogger(str(test_dir))
    
    # LLMæ•™å¸«åˆæœŸåŒ–
    llm_teacher = LLMTeacher(api_key=api_key, model="gpt-4o-mini")
    
    # ç’°å¢ƒåˆæœŸåŒ–
    env = TowerDefenseEnvironment()
    env.reset(seed=42)
    
    print("\nğŸ§ª Testing LLM interaction logging...")
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: åŸºæœ¬çš„ãªLLMå‘¼ã³å‡ºã—
    print("\n1. Basic LLM call test:")
    try:
        start_time = time.time()
        evaluation = llm_teacher.evaluate_state_and_recommend(env)
        api_time = time.time() - start_time
        
        print(f"   âœ… LLM Response: {evaluation[:100]}...")
        print(f"   â±ï¸  API Time: {api_time:.2f}s")
        
        # ãƒ­ã‚°è¨˜éŒ²
        llm_logger.log_interaction(
            episode=1,
            step=1,
            prompt=llm_teacher.get_last_prompt(),
            response=evaluation,
            decision=evaluation,
            adopted=True
        )
        
        print("   âœ… Interaction logged successfully")
        
    except Exception as e:
        print(f"   âŒ LLM call failed: {e}")
        return False
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: è¤‡æ•°å›ã®å‘¼ã³å‡ºã—
    print("\n2. Multiple LLM calls test:")
    for i in range(3):
        try:
            # ç’°å¢ƒçŠ¶æ…‹ã‚’å°‘ã—å¤‰æ›´
            env.money += 100 * i
            env.wave += i
            
            evaluation = llm_teacher.evaluate_state_and_recommend(env)
            
            llm_logger.log_interaction(
                episode=1,
                step=i+2,
                prompt=llm_teacher.get_last_prompt(),
                response=evaluation,
                decision=f"test_decision_{i}",
                adopted=i % 2 == 0  # äº¤äº’ã«æ¡ç”¨/éæ¡ç”¨
            )
            
            print(f"   âœ… Call {i+1}: {evaluation[:50]}...")
            
        except Exception as e:
            print(f"   âŒ Call {i+1} failed: {e}")
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3: APIçµ±è¨ˆã®ç¢ºèª
    print("\n3. API statistics test:")
    stats = llm_teacher.get_api_stats()
    print(f"   ğŸ“Š Total calls: {stats['total_calls']}")
    print(f"   âœ… Successful calls: {stats['successful_calls']}")
    print(f"   âŒ Failed calls: {stats['failed_calls']}")
    print(f"   ğŸ“ˆ Success rate: {stats['success_rate']:.2%}")
    print(f"   â±ï¸  Average API time: {stats['avg_api_time']:.2f}s")
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    print("\n4. Log file verification:")
    log_file = test_dir / "llm_interactions.jsonl"
    if log_file.exists():
        with log_file.open('r') as f:
            lines = f.readlines()
        print(f"   âœ… Log file created: {len(lines)} interactions logged")
        
        # æœ€åˆã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’è¡¨ç¤º
        if lines:
            import json
            first_entry = json.loads(lines[0])
            print(f"   ğŸ“ First entry keys: {list(first_entry.keys())}")
            print(f"   ğŸ”‘ Prompt ID: {first_entry.get('prompt_id', 'N/A')}")
    else:
        print("   âŒ Log file not found")
        return False
    
    print(f"\nâœ… LLM interaction logging test completed successfully!")
    print(f"ğŸ“ Test results saved to: {test_dir}")
    
    return True


def test_llm_teacher_fallback():
    """LLMæ•™å¸«ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ”„ Testing LLM teacher fallback mode...")
    
    # APIã‚­ãƒ¼ãªã—ã§ãƒ†ã‚¹ãƒˆ
    llm_teacher = LLMTeacher(api_key=None)
    env = TowerDefenseEnvironment()
    env.reset(seed=42)
    
    try:
        evaluation = llm_teacher.evaluate_state_and_recommend(env)
        print(f"   âœ… Fallback response: {evaluation}")
        
        stats = llm_teacher.get_api_stats()
        print(f"   ğŸ“Š Fallback stats: {stats}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Fallback test failed: {e}")
        return False


if __name__ == "__main__":
    print("ğŸš€ Starting LLM interaction logging tests...")
    
    # ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ
    success = test_llm_interaction_logging()
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    fallback_success = test_llm_teacher_fallback()
    
    if success and fallback_success:
        print("\nğŸ‰ All tests passed!")
    else:
        print("\nğŸ’¥ Some tests failed!")
        exit(1)
