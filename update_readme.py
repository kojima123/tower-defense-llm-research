#!/usr/bin/env python3
"""
å®Ÿæ¸¬çµæœã‹ã‚‰ã®è‡ªå‹•READMEæ›´æ–°ã‚·ã‚¹ãƒ†ãƒ 
åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åˆ‡ä½¿ç”¨ã›ãšã€å®Ÿéš›ã®å®Ÿé¨“çµæœã®ã¿ã‹ã‚‰READMEã‚’ç”Ÿæˆãƒ»æ›´æ–°
"""
import json
import pandas as pd
from pathlib import Path
import argparse
from datetime import datetime
from typing import Dict, List, Any, Optional
import re


class ReadmeUpdater:
    """å®Ÿæ¸¬çµæœãƒ™ãƒ¼ã‚¹READMEæ›´æ–°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, project_dir: str):
        self.project_dir = Path(project_dir)
        self.readme_path = self.project_dir / "README.md"
        self.results_data = {}
        
    def load_experiment_results(self, results_dir: str) -> bool:
        """å®Ÿé¨“çµæœã‚’èª­ã¿è¾¼ã¿"""
        results_path = Path(results_dir)
        
        print("ğŸ“Š Loading experiment results for README update...")
        
        # å®Ÿé¨“ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        summary_files = list(results_path.glob("**/experiment_summary*.json"))
        if not summary_files:
            print("   âš ï¸  No experiment summary found")
            return False
        
        # æœ€æ–°ã®ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        latest_summary = max(summary_files, key=lambda x: x.stat().st_mtime)
        print(f"   ğŸ“ Loading: {latest_summary}")
        
        try:
            with latest_summary.open('r') as f:
                self.results_data = json.load(f)
            
            print(f"   âœ… Loaded results for {len(self.results_data.get('results', {}))} conditions")
            return True
            
        except Exception as e:
            print(f"   âŒ Failed to load results: {e}")
            return False
    
    def load_analysis_results(self, analysis_dir: str) -> Dict[str, Any]:
        """åˆ†æçµæœã‚’èª­ã¿è¾¼ã¿"""
        analysis_path = Path(analysis_dir)
        analysis_data = {}
        
        # åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’æ¢ã™
        report_files = list(analysis_path.glob("**/real_data_analysis_report.md"))
        if report_files:
            latest_report = max(report_files, key=lambda x: x.stat().st_mtime)
            analysis_data["report_path"] = str(latest_report)
            print(f"   ğŸ“Š Found analysis report: {latest_report}")
        
        # å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        viz_files = list(analysis_path.glob("**/real_data_analysis.png"))
        if viz_files:
            latest_viz = max(viz_files, key=lambda x: x.stat().st_mtime)
            analysis_data["visualization_path"] = str(latest_viz)
            print(f"   ğŸ“ˆ Found visualization: {latest_viz}")
        
        # LLMã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³åˆ†æã‚’æ¢ã™
        llm_files = list(analysis_path.glob("**/llm_interaction_analysis.md"))
        if llm_files:
            latest_llm = max(llm_files, key=lambda x: x.stat().st_mtime)
            analysis_data["llm_analysis_path"] = str(latest_llm)
            print(f"   ğŸ¤– Found LLM analysis: {latest_llm}")
        
        return analysis_data
    
    def extract_performance_summary(self) -> Dict[str, Any]:
        """å®Ÿé¨“çµæœã‹ã‚‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ã‚’æŠ½å‡º"""
        if not self.results_data or "results" not in self.results_data:
            return {}\n        \n        summary = {\n            "experiment_date": datetime.now().strftime("%Y-%m-%d"),\n            "total_conditions": len(self.results_data["results"]),\n            "seeds_used": self.results_data.get("seeds", []),\n            "episodes_per_condition": self.results_data.get("total_episodes_per_condition", 0),\n            "conditions": {}\n        }\n        \n        # æ¡ä»¶åˆ¥çµæœã®æŠ½å‡º\n        for condition, data in self.results_data["results"].items():\n            if "results" in data and data["results"]:\n                scores = [r["mean_score"] for r in data["results"]]\n                \n                condition_summary = {\n                    "mean_score": sum(scores) / len(scores),\n                    "std_score": (sum((s - sum(scores)/len(scores))**2 for s in scores) / len(scores))**0.5,\n                    "min_score": min(scores),\n                    "max_score": max(scores),\n                    "sample_size": len(scores),\n                    "total_time": data.get("total_time", 0)\n                }\n                \n                summary["conditions"][condition] = condition_summary\n        \n        # æœ€é«˜æ€§èƒ½æ¡ä»¶ã®ç‰¹å®š\n        if summary["conditions"]:\n            best_condition = max(summary["conditions"].items(), \n                               key=lambda x: x[1]["mean_score"])\n            summary["best_condition"] = {\n                "name": best_condition[0],\n                "score": best_condition[1]["mean_score"]\n            }\n        \n        return summary\n    \n    def generate_results_section(self, performance_summary: Dict[str, Any]) -> str:\n        """å®Ÿé¨“çµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""\n        if not performance_summary:\n            return "## å®Ÿé¨“çµæœ\\n\\n*å®Ÿé¨“çµæœã¯ã¾ã åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚*\\n"\n        \n        section = f"""## å®Ÿé¨“çµæœ\n\n### æœ€æ–°å®Ÿé¨“ ({performance_summary['experiment_date']})\n\n**å®Ÿé¨“è¨­å®š:**\n- æ¡ä»¶æ•°: {performance_summary['total_conditions']}\n- ä½¿ç”¨ã‚·ãƒ¼ãƒ‰: {performance_summary['seeds_used']}\n- ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°/æ¡ä»¶: {performance_summary['episodes_per_condition']}\n- ãƒ‡ãƒ¼ã‚¿å“è³ª: âœ… å®Ÿæ¸¬ã®ã¿ï¼ˆåˆæˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰\n\n### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ\n\n| æ¡ä»¶ | å¹³å‡ã‚¹ã‚³ã‚¢ | æ¨™æº–åå·® | æœ€å°-æœ€å¤§ | ã‚µãƒ³ãƒ—ãƒ«æ•° |\n|------|------------|----------|-----------|------------|\n"""\n        \n        # æ¡ä»¶åˆ¥çµæœãƒ†ãƒ¼ãƒ–ãƒ«\n        for condition, stats in performance_summary["conditions"].items():\n            section += f"| {condition} | {stats['mean_score']:.2f} | {stats['std_score']:.2f} | {stats['min_score']:.0f}-{stats['max_score']:.0f} | {stats['sample_size']} |\\n"\n        \n        # æœ€é«˜æ€§èƒ½ã®å¼·èª¿\n        if "best_condition" in performance_summary:\n            best = performance_summary["best_condition"]\n            section += f\"\\n**ğŸ† æœ€é«˜æ€§èƒ½**: {best['name']} (å¹³å‡ã‚¹ã‚³ã‚¢: {best['score']:.2f})\\n\"\n        \n        section += \"\\n### ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼\\n\\n\"\n        section += \"- âœ… **å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ã¿**: åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¯ä¸€åˆ‡ãªã—\\n\"\n        section += \"- âœ… **å†ç¾å¯èƒ½æ€§**: å›ºå®šã‚·ãƒ¼ãƒ‰å®Ÿé¨“\\n\"\n        section += \"- âœ… **é€æ˜æ€§**: å…¨å®Ÿé¨“ãƒ­ã‚°å…¬é–‹\\n\"\n        section += \"- âœ… **çµ±è¨ˆçš„å¦¥å½“æ€§**: é©åˆ‡ãªæ¤œå®šæ‰‹æ³•ä½¿ç”¨\\n\\n\"\n        \n        return section\n    \n    def generate_technical_details(self) -> str:\n        \"\"\"æŠ€è¡“è©³ç´°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ\"\"\"\n        return \"\"\"## æŠ€è¡“è©³ç´°\n\n### ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ\n\n- **ELM (Extreme Learning Machine)**: é«˜é€Ÿå­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ \n- **LLM Teacher**: OpenAI GPT-4o-mini ã«ã‚ˆã‚‹æˆ¦ç•¥æŒ‡å°\n- **ç’°å¢ƒ**: Tower Defense ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼\n- **ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ **: CSV + JSON + JSONL å½¢å¼\n\n### å®Ÿé¨“æ¡ä»¶\n\n1. **ELMå˜ä½“**: ELMã®ã¿ã§ã®å­¦ç¿’\n2. **ãƒ«ãƒ¼ãƒ«æ•™å¸«**: äº‹å‰å®šç¾©ãƒ«ãƒ¼ãƒ«ã«ã‚ˆã‚‹æŒ‡å°\n3. **ãƒ©ãƒ³ãƒ€ãƒ æ•™å¸«**: ãƒ©ãƒ³ãƒ€ãƒ ãªè¡Œå‹•æŒ‡å°\n4. **ELM+LLM**: LLMã«ã‚ˆã‚‹æˆ¦ç•¥çš„æŒ‡å°\n\n### ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\n\n```\nå®Ÿé¨“å®Ÿè¡Œ â†’ ãƒ­ã‚°è¨˜éŒ² â†’ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ â†’ çµ±è¨ˆåˆ†æ â†’ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\n```\n\n- **åˆæˆãƒ‡ãƒ¼ã‚¿æ¤œå‡º**: è‡ªå‹•çš„ã«æ’é™¤\n- **è¨­å®šãƒãƒƒã‚·ãƒ¥**: å®Ÿé¨“æ¡ä»¶ã®å³å¯†ç®¡ç†\n- **çµ±è¨ˆæ¤œå®š**: scipy.stats ã«ã‚ˆã‚‹ç§‘å­¦çš„åˆ†æ\n\n\"\"\"\n    \n    def generate_usage_section(self) -> str:\n        \"\"\"ä½¿ç”¨æ–¹æ³•ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ\"\"\"\n        return \"\"\"## ä½¿ç”¨æ–¹æ³•\n\n### åŸºæœ¬å®Ÿé¨“ã®å®Ÿè¡Œ\n\n```bash\n# 4æ¡ä»¶æ¯”è¼ƒå®Ÿé¨“ï¼ˆæ¨å¥¨ï¼‰\npython run_fixed_seed_experiments.py --episodes 20\n\n# å˜ä¸€æ¡ä»¶å®Ÿé¨“\npython run_elm_real.py --condition elm_only --episodes 10 --seed 42\n\n# LLMå®Ÿé¨“ï¼ˆOpenAI APIã‚­ãƒ¼å¿…è¦ï¼‰\nexport OPENAI_API_KEY=\"your-api-key\"\npython run_elm_llm_real.py --episodes 10 --seed 42\n```\n\n### åˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\n\n```bash\n# å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿åˆ†æ\npython analyze_real_data.py runs/real/experiment_name/\n\n# LLMã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³åˆ†æ\npython analyze_llm_interactions.py runs/real/experiment_name/elm_llm/seed_42/\n\n# å®Œå…¨å®Ÿé¨“ï¼ˆå®Ÿè¡Œ+åˆ†æï¼‰\npython run_complete_experiment.py --episodes 20\n```\n\n### çµæœã®ç¢ºèª\n\n- **å®Ÿé¨“ãƒ­ã‚°**: `runs/real/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n- **åˆ†æãƒ¬ãƒãƒ¼ãƒˆ**: `*_analysis_report.md`\n- **å¯è¦–åŒ–**: `*.png` ãƒ•ã‚¡ã‚¤ãƒ«\n- **çµ±è¨ˆçµæœ**: JSONå½¢å¼ã®ã‚µãƒãƒªãƒ¼\n\n\"\"\"\n    \n    def create_readme_template(self) -> str:\n        \"\"\"READMEãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ\"\"\"\n        return \"\"\"# Tower Defense ELM+LLM Research Project\n\n**ç§‘å­¦çš„å³å¯†æ€§ã‚’é‡è¦–ã—ãŸã‚¿ãƒ¯ãƒ¼ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚¹å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ **\n\n[![Data Quality](https://img.shields.io/badge/Data-Real%20Only-green)]()\n[![Reproducibility](https://img.shields.io/badge/Reproducibility-Fixed%20Seeds-blue)]()\n[![Transparency](https://img.shields.io/badge/Transparency-Full%20Logs-orange)]()\n\n## æ¦‚è¦\n\nã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ELMï¼ˆExtreme Learning Machineï¼‰ã¨LLMï¼ˆLarge Language Modelï¼‰ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¿ãƒ¯ãƒ¼ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚¹å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚**å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ã¿**ã‚’ä½¿ç”¨ã—ã€åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åˆ‡ä½¿ç”¨ã—ãªã„ç§‘å­¦çš„ã«å³å¯†ãªå®Ÿé¨“ã‚’å®Ÿæ–½ã—ã¦ã„ã¾ã™ã€‚\n\n### ä¸»è¦ç‰¹å¾´\n\n- ğŸ”¬ **ç§‘å­¦çš„å³å¯†æ€§**: å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ã¿ã€åˆæˆãƒ‡ãƒ¼ã‚¿å®Œå…¨æ’é™¤\n- ğŸ”„ **å®Œå…¨å†ç¾å¯èƒ½**: å›ºå®šã‚·ãƒ¼ãƒ‰ã€è¨­å®šãƒãƒƒã‚·ãƒ¥ç®¡ç†\n- ğŸ“Š **çµ±è¨ˆçš„å¦¥å½“æ€§**: é©åˆ‡ãªæ¤œå®šæ‰‹æ³•ã«ã‚ˆã‚‹åˆ†æ\n- ğŸ¤– **LLMçµ±åˆ**: OpenAI GPT-4o-mini ã«ã‚ˆã‚‹æˆ¦ç•¥æŒ‡å°\n- ğŸ“ **é€æ˜æ€§**: å…¨å®Ÿé¨“ãƒ­ã‚°ã®å…¬é–‹ãƒ»æ¤œè¨¼å¯èƒ½\n\n{RESULTS_SECTION}\n\n{TECHNICAL_DETAILS}\n\n{USAGE_SECTION}\n\n## ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ\n\n```\nâ”œâ”€â”€ run_fixed_seed_experiments.py  # 4æ¡ä»¶æ¯”è¼ƒå®Ÿé¨“\nâ”œâ”€â”€ run_elm_real.py                # ELMå˜ä½“å®Ÿé¨“\nâ”œâ”€â”€ run_elm_llm_real.py            # ELM+LLMå®Ÿé¨“\nâ”œâ”€â”€ analyze_real_data.py           # å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿åˆ†æ\nâ”œâ”€â”€ logger.py                      # å®Ÿæ¸¬å°‚ç”¨ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ \nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ tower_defense_environment.py\nâ”‚   â”œâ”€â”€ elm_tower_defense_agent.py\nâ”‚   â””â”€â”€ llm_teacher.py\nâ””â”€â”€ runs/real/                     # å®Ÿæ¸¬å®Ÿé¨“ãƒ­ã‚°\n```\n\n## ç ”ç©¶ã®ä¿¡é ¼æ€§\n\n### ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼\n\n- âœ… **å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ã¿**: `validate_no_synthetic_data()` ã«ã‚ˆã‚‹æ¤œè¨¼\n- âœ… **å›ºå®šã‚·ãƒ¼ãƒ‰å®Ÿé¨“**: å®Œå…¨ãªå†ç¾å¯èƒ½æ€§\n- âœ… **è¨­å®šãƒãƒƒã‚·ãƒ¥**: å®Ÿé¨“æ¡ä»¶ã®å³å¯†ãªè¿½è·¡\n- âœ… **ãƒ­ã‚°æ•´åˆæ€§**: è‡ªå‹•æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ \n\n### çµ±è¨ˆåˆ†æ\n\n- ğŸ“Š **è¨˜è¿°çµ±è¨ˆ**: å¹³å‡ã€æ¨™æº–åå·®ã€ç¯„å›²ã€ä¸­å¤®å€¤\n- ğŸ§ª **æ¤œå®š**: Shapiro-Wilkã€Leveneã€ANOVA/Kruskal-Wallis\n- ğŸ“ˆ **åŠ¹æœé‡**: Cohen's d ã«ã‚ˆã‚‹å®Ÿç”¨çš„æœ‰æ„æ€§\n- ğŸ¯ **å¤šé‡æ¯”è¼ƒ**: Mann-Whitney Uæ¤œå®š\n\n## è²¢çŒ®\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n**æ³¨æ„**: å…¨ã¦ã®è²¢çŒ®ã¯å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã—ã€åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’å«ã¾ãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n\nMIT License - è©³ç´°ã¯ [LICENSE](LICENSE) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§\n\n## å¼•ç”¨\n\n```bibtex\n@software{tower_defense_elm_llm,\n  title={Tower Defense ELM+LLM Research Project},\n  author={Research Team},\n  year={2025},\n  url={https://github.com/your-repo/tower-defense-llm}\n}\n```\n\n---\n\n*ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã—ã€ç§‘å­¦çš„å³å¯†æ€§ã‚’æœ€å„ªå…ˆã«é–‹ç™ºã•ã‚Œã¦ã„ã¾ã™ã€‚*\n\"\"\"\n    \n    def update_readme(self, results_dir: str, analysis_dir: str = None) -> bool:\n        \"\"\"READMEã‚’å®Ÿæ¸¬çµæœã§æ›´æ–°\"\"\"\n        print(\"ğŸ“ Updating README with real experimental results...\")\n        \n        # å®Ÿé¨“çµæœèª­ã¿è¾¼ã¿\n        if not self.load_experiment_results(results_dir):\n            return False\n        \n        # åˆ†æçµæœèª­ã¿è¾¼ã¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n        analysis_data = {}\n        if analysis_dir:\n            analysis_data = self.load_analysis_results(analysis_dir)\n        \n        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼æŠ½å‡º\n        performance_summary = self.extract_performance_summary()\n        \n        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ\n        results_section = self.generate_results_section(performance_summary)\n        technical_details = self.generate_technical_details()\n        usage_section = self.generate_usage_section()\n        \n        # READMEãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ\n        readme_content = self.create_readme_template()\n        \n        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç½®æ›\n        readme_content = readme_content.replace(\"{RESULTS_SECTION}\", results_section)\n        readme_content = readme_content.replace(\"{TECHNICAL_DETAILS}\", technical_details)\n        readme_content = readme_content.replace(\"{USAGE_SECTION}\", usage_section)\n        \n        # åˆ†æçµæœã¸ã®ãƒªãƒ³ã‚¯è¿½åŠ \n        if analysis_data:\n            links_section = \"\\n## è©³ç´°åˆ†æ\\n\\n\"\n            if \"report_path\" in analysis_data:\n                links_section += f\"- ğŸ“Š [çµ±è¨ˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ]({analysis_data['report_path']})\\n\"\n            if \"visualization_path\" in analysis_data:\n                links_section += f\"- ğŸ“ˆ [çµæœå¯è¦–åŒ–]({analysis_data['visualization_path']})\\n\"\n            if \"llm_analysis_path\" in analysis_data:\n                links_section += f\"- ğŸ¤– [LLMã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³åˆ†æ]({analysis_data['llm_analysis_path']})\\n\"\n            \n            readme_content = readme_content.replace(\"## ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ\", links_section + \"\\n## ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ\")\n        \n        # READMEä¿å­˜\n        try:\n            with self.readme_path.open('w', encoding='utf-8') as f:\n                f.write(readme_content)\n            \n            print(f\"   âœ… README updated: {self.readme_path}\")\n            print(f\"   ğŸ“Š Included {len(performance_summary.get('conditions', {}))} conditions\")\n            \n            if \"best_condition\" in performance_summary:\n                best = performance_summary[\"best_condition\"]\n                print(f\"   ğŸ† Best performance: {best['name']} ({best['score']:.2f})\")\n            \n            return True\n            \n        except Exception as e:\n            print(f\"   âŒ Failed to write README: {e}\")\n            return False\n    \n    def backup_existing_readme(self) -> bool:\n        \"\"\"æ—¢å­˜ã®READMEã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\"\"\"\n        if self.readme_path.exists():\n            backup_path = self.readme_path.with_suffix('.md.backup')\n            try:\n                backup_path.write_text(self.readme_path.read_text(encoding='utf-8'), encoding='utf-8')\n                print(f\"   ğŸ’¾ Existing README backed up to: {backup_path}\")\n                return True\n            except Exception as e:\n                print(f\"   âš ï¸  Failed to backup README: {e}\")\n                return False\n        return True\n\n\ndef main():\n    \"\"\"ãƒ¡ã‚¤ãƒ³é–¢æ•°\"\"\"\n    parser = argparse.ArgumentParser(description=\"Update README with real experimental results\")\n    parser.add_argument(\"results_dir\", help=\"Directory containing experiment results\")\n    parser.add_argument(\"--analysis_dir\", help=\"Directory containing analysis results\")\n    parser.add_argument(\"--project_dir\", default=\".\", help=\"Project root directory\")\n    parser.add_argument(\"--backup\", action=\"store_true\", help=\"Backup existing README\")\n    \n    args = parser.parse_args()\n    \n    # READMEæ›´æ–°å®Ÿè¡Œ\n    updater = ReadmeUpdater(args.project_dir)\n    \n    if args.backup:\n        updater.backup_existing_readme()\n    \n    success = updater.update_readme(args.results_dir, args.analysis_dir)\n    \n    if success:\n        print(\"\\nâœ… README successfully updated with real experimental results!\")\n    else:\n        print(\"\\nâŒ Failed to update README\")\n        exit(1)\n\n\nif __name__ == \"__main__\":\n    main()
