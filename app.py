#!/usr/bin/env python3
"""
Flask server for Tower Defense LLM Trainer - Deployment Version
Handles LLM guidance requests and ELM integration for tower defense game
"""

from flask import Flask, request, jsonify, send_from_directory, render_template_string
from flask_cors import CORS
import os
import json
import time
import random
import numpy as np
from openai import OpenAI

app = Flask(__name__, static_folder='static', static_url_path='')
CORS(app)

# Initialize OpenAI client
client = None
if os.getenv('OPENAI_API_KEY'):
    try:
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        print("âœ… OpenAI client initialized")
    except Exception as e:
        print(f"âŒ OpenAI initialization failed: {e}")

# Tower Defense ELM implementation
class TowerDefenseELM:
    def __init__(self, input_size=8, hidden_size=20, output_size=2, random_state=42):
        """
        ELM for Tower Defense strategy
        Input: [money, health, wave, enemies, towers, efficiency, survival, progress]
        Output: [place_tower_probability, tower_x_position]
        """
        np.random.seed(random_state)
        self.input_weights = np.random.randn(input_size, hidden_size) * 0.5
        self.hidden_bias = np.random.randn(hidden_size) * 0.5
        self.output_weights = np.random.randn(hidden_size, output_size) * 0.1
        self.learning_rate = 0.02
        
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
    
    def tanh(self, x):
        return np.tanh(np.clip(x, -500, 500))
    
    def predict(self, x):
        x = np.array(x).reshape(1, -1)
        # Normalize inputs
        x = x / np.maximum(np.abs(x), 1e-8)
        
        hidden = self.tanh(np.dot(x, self.input_weights) + self.hidden_bias)
        output = np.dot(hidden, self.output_weights)
        
        # Apply sigmoid to tower placement probability
        output[0, 0] = self.sigmoid(output[0, 0])
        # Normalize tower position to [0, 1]
        output[0, 1] = self.sigmoid(output[0, 1])
        
        return output[0]
    
    def update(self, x, target, learning_rate=None):
        if learning_rate is None:
            learning_rate = self.learning_rate
            
        x = np.array(x).reshape(1, -1)
        target = np.array(target).reshape(1, -1)
        
        # Normalize inputs
        x = x / np.maximum(np.abs(x), 1e-8)
        
        # Forward pass
        hidden = self.tanh(np.dot(x, self.input_weights) + self.hidden_bias)
        output = np.dot(hidden, self.output_weights)
        
        # Apply activations
        output[0, 0] = self.sigmoid(output[0, 0])
        output[0, 1] = self.sigmoid(output[0, 1])
        
        # Simple gradient update
        error = target - output
        self.output_weights += learning_rate * np.dot(hidden.T, error)

# Global model instances
baseline_elm = TowerDefenseELM(random_state=42)
llm_guided_elm = TowerDefenseELM(random_state=43)

# Game state tracking
game_sessions = {}

@app.route('/')
def index():
    """Serve the main game page"""
    try:
        return send_from_directory('static', 'index.html')
    except:
        # Fallback to static.html in root directory
        return send_from_directory('.', 'static.html')

@app.route('/health')
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'openai_available': client is not None,
        'timestamp': time.time()
    })

@app.route('/api/llm-guidance', methods=['POST'])
def get_llm_guidance():
    """Get strategic guidance from LLM based on current game state"""
    try:
        data = request.json
        game_state = data['game_state']
        
        if not client:
            # Fallback to rule-based guidance
            return get_rule_based_guidance(game_state)
        
        try:
            prompt = f"""
ã‚ãªãŸã¯ã‚¿ãƒ¯ãƒ¼ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚¹ã‚²ãƒ¼ãƒ ã®æˆ¦ç•¥ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚ç¾åœ¨ã®ã‚²ãƒ¼ãƒ çŠ¶æ³ã‚’åˆ†æã—ã€æœ€é©ãªæˆ¦ç•¥ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ç¾åœ¨ã®çŠ¶æ³:
- è³‡é‡‘: ${game_state['money']}
- ãƒ˜ãƒ«ã‚¹: {game_state['health']}
- ã‚¦ã‚§ãƒ¼ãƒ–: {game_state['wave']}
- æ•µã®æ•°: {game_state['enemies']}
- ã‚¿ãƒ¯ãƒ¼æ•°: {game_state['towers']}
- ã‚¹ã‚³ã‚¢: {game_state['score']}
- åŠ¹ç‡æ€§: {game_state.get('efficiency', 0):.2f}
- ç”Ÿå­˜ç‡: {game_state.get('survival', 1):.2f}

ã‚¿ãƒ¯ãƒ¼ã‚³ã‚¹ãƒˆ: $50
ã‚¿ãƒ¯ãƒ¼ãƒ€ãƒ¡ãƒ¼ã‚¸: 60
ã‚¿ãƒ¯ãƒ¼å°„ç¨‹: 150

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
å„ªå…ˆåº¦: [urgent/high/medium/low]
æ¨å¥¨è¡Œå‹•: [å…·ä½“çš„ãªè¡Œå‹•]
ç†ç”±: [æˆ¦ç•¥çš„ãªç†ç”±]
"""
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200,
                temperature=0.7
            )
            
            content = response.choices[0].message.content.strip()
            
            # Parse LLM response
            lines = content.split('\n')
            priority = 'medium'
            recommendation = 'ã‚¿ãƒ¯ãƒ¼ã‚’é…ç½®ã—ã¦ãã ã•ã„'
            reasoning = 'é˜²å¾¡ã‚’å¼·åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™'
            
            for line in lines:
                if 'å„ªå…ˆåº¦:' in line:
                    priority_text = line.split(':', 1)[1].strip()
                    if 'urgent' in priority_text or 'ç·Šæ€¥' in priority_text:
                        priority = 'urgent'
                    elif 'high' in priority_text or 'é«˜' in priority_text:
                        priority = 'high'
                    elif 'low' in priority_text or 'ä½' in priority_text:
                        priority = 'low'
                elif 'æ¨å¥¨è¡Œå‹•:' in line or 'æ¨å¥¨' in line:
                    recommendation = line.split(':', 1)[1].strip()
                elif 'ç†ç”±:' in line:
                    reasoning = line.split(':', 1)[1].strip()
            
            return jsonify({
                'recommendation': recommendation,
                'reasoning': reasoning,
                'priority': priority,
                'source': 'llm'
            })
            
        except Exception as e:
            print(f"LLM guidance failed: {e}")
            return get_rule_based_guidance(game_state)
            
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def get_rule_based_guidance(game_state):
    """Fallback rule-based guidance system"""
    money = game_state['money']
    health = game_state['health']
    wave = game_state['wave']
    enemies = game_state['enemies']
    towers = game_state['towers']
    
    if health < 30:
        return jsonify({
            'recommendation': 'ç·Šæ€¥ã§ã‚¿ãƒ¯ãƒ¼ã‚’é…ç½®ã—ã¦ãã ã•ã„ï¼',
            'reasoning': 'ãƒ˜ãƒ«ã‚¹ãŒå±é™ºãªçŠ¶æ…‹ã§ã™',
            'priority': 'urgent',
            'source': 'rule_based'
        })
    elif money >= 100 and towers < wave:
        return jsonify({
            'recommendation': 'ã‚¿ãƒ¯ãƒ¼ã‚’è¿½åŠ é…ç½®ã—ã¾ã—ã‚‡ã†',
            'reasoning': 'ååˆ†ãªè³‡é‡‘ãŒã‚ã‚Šã€ã‚¦ã‚§ãƒ¼ãƒ–ã«å¯¾ã—ã¦ã‚¿ãƒ¯ãƒ¼ãŒä¸è¶³ã—ã¦ã„ã¾ã™',
            'priority': 'high',
            'source': 'rule_based'
        })
    elif enemies > 5 and towers < 3:
        return jsonify({
            'recommendation': 'ã‚¿ãƒ¯ãƒ¼ã‚’é…ç½®ã—ã¦é˜²å¾¡ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„',
            'reasoning': 'æ•µã®æ•°ãŒå¤šãã€é˜²å¾¡ãŒä¸ååˆ†ã§ã™',
            'priority': 'high',
            'source': 'rule_based'
        })
    elif money >= 50:
        return jsonify({
            'recommendation': 'ã‚¿ãƒ¯ãƒ¼ã‚’é…ç½®ã—ã¦é˜²å¾¡ã‚’æ‹¡å¼µã—ã¾ã—ã‚‡ã†',
            'reasoning': 'è³‡é‡‘ã«ä½™è£•ãŒã‚ã‚Šã¾ã™',
            'priority': 'medium',
            'source': 'rule_based'
        })
    else:
        return jsonify({
            'recommendation': 'ç¾åœ¨ã®æˆ¦ç•¥ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„',
            'reasoning': 'è‰¯å¥½ãªçŠ¶æ…‹ã‚’ç¶­æŒã—ã¦ã„ã¾ã™',
            'priority': 'low',
            'source': 'rule_based'
        })

@app.route('/api/elm-predict', methods=['POST'])
def elm_predict():
    """Get ELM prediction for tower placement"""
    try:
        data = request.json
        game_state = data['game_state']
        model_type = data.get('model_type', 'baseline')
        
        # Prepare input features
        features = [
            game_state['money'] / 1000.0,  # Normalize money
            game_state['health'] / 100.0,  # Normalize health
            game_state['wave'] / 10.0,     # Normalize wave
            game_state['enemies'] / 10.0,  # Normalize enemies
            game_state['towers'] / 10.0,   # Normalize towers
            game_state.get('efficiency', 0),
            game_state.get('survival', 1),
            game_state.get('progress', 1) / 10.0
        ]
        
        if model_type == 'llm_guided':
            prediction = llm_guided_elm.predict(features)
        else:
            prediction = baseline_elm.predict(features)
        
        # Convert prediction to actionable format
        should_place_tower = prediction[0] > 0.5
        tower_position_ratio = prediction[1]
        
        return jsonify({
            'should_place_tower': bool(should_place_tower),
            'placement_probability': float(prediction[0]),
            'position_ratio': float(tower_position_ratio),
            'confidence': float(abs(prediction[0] - 0.5) * 2)
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/elm-update', methods=['POST'])
def elm_update():
    """Update ELM model based on performance feedback"""
    try:
        data = request.json
        game_state = data['game_state']
        action_taken = data['action_taken']
        performance_score = data['performance_score']
        model_type = data.get('model_type', 'llm_guided')
        
        # Prepare input features
        features = [
            game_state['money'] / 1000.0,
            game_state['health'] / 100.0,
            game_state['wave'] / 10.0,
            game_state['enemies'] / 10.0,
            game_state['towers'] / 10.0,
            game_state.get('efficiency', 0),
            game_state.get('survival', 1),
            game_state.get('progress', 1) / 10.0
        ]
        
        # Create target based on performance
        target = [
            performance_score if action_taken['placed_tower'] else 1 - performance_score,
            action_taken.get('position_ratio', 0.5)
        ]
        
        # Adaptive learning rate
        learning_rate = 0.01 * (performance_score + 0.1)
        
        if model_type == 'llm_guided':
            llm_guided_elm.update(features, target, learning_rate)
        else:
            baseline_elm.update(features, target, learning_rate)
        
        return jsonify({
            'status': 'updated',
            'learning_rate': learning_rate,
            'target': target
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/evaluate-performance', methods=['POST'])
def evaluate_performance():
    """Evaluate current game performance"""
    try:
        data = request.json
        game_state = data['game_state']
        previous_state = data.get('previous_state', {})
        
        # Calculate performance metrics
        score_improvement = game_state['score'] - previous_state.get('score', 0)
        health_ratio = game_state['health'] / 100.0
        efficiency = game_state.get('efficiency', 0)
        
        # Composite performance score
        performance = (
            min(score_improvement / 100.0, 1.0) * 0.4 +  # Score improvement
            health_ratio * 0.3 +                          # Health preservation
            min(efficiency, 1.0) * 0.3                    # Tower efficiency
        )
        
        performance = max(0.0, min(1.0, performance))
        
        return jsonify({
            'performance_score': performance,
            'metrics': {
                'score_improvement': score_improvement,
                'health_ratio': health_ratio,
                'efficiency': efficiency
            }
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/reset-models', methods=['POST'])
def reset_models():
    """Reset both ELM models to initial state"""
    global baseline_elm, llm_guided_elm
    baseline_elm = TowerDefenseELM(random_state=42)
    llm_guided_elm = TowerDefenseELM(random_state=43)
    return jsonify({'status': 'reset'})

if __name__ == '__main__':
    print("ğŸš€ Starting Tower Defense LLM Trainer Server (Deployment)")
    print(f"ğŸ”‘ OpenAI API: {'âœ… Available' if client else 'âŒ Not available'}")
    print("ğŸ® Game available at: http://0.0.0.0:5000")
    app.run(host='0.0.0.0', port=5000, debug=False)
