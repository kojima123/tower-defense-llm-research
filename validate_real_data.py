#!/usr/bin/env python3
"""
å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
åˆæˆãƒ‡ãƒ¼ã‚¿ã®æ··å…¥ã‚’æ¤œå‡ºã—ã€å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ã¿ã®ä½¿ç”¨ã‚’ä¿è¨¼ã™ã‚‹
"""
import os
import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any, Tuple
import hashlib
import ast


class RealDataValidator:
    """å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, project_dir: str = "."):
        self.project_dir = Path(project_dir)
        self.real_data_dir = self.project_dir / "runs" / "real"
        self.synthetic_data_indicators = [
            "np.random",
            "random.seed",
            "random.normal",
            "random.uniform",
            "random.choice",
            "simulate_",
            "generate_synthetic",
            "fake_data",
            "mock_data"
        ]
        
    def validate_no_synthetic_data(self) -> Tuple[bool, List[str]]:
        """åˆæˆãƒ‡ãƒ¼ã‚¿ã®ä½¿ç”¨ãŒãªã„ã“ã¨ã‚’æ¤œè¨¼"""
        print("ğŸ” Validating no synthetic data usage...")
        
        violations = []
        
        # Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
        python_files = list(self.project_dir.glob("*.py"))
        python_files.extend(list(self.project_dir.glob("src/*.py")))
        
        for py_file in python_files:
            if self._contains_synthetic_data_code(py_file):
                violations.append(f"Python file contains synthetic data: {py_file}")
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
        json_files = list(self.project_dir.glob("*.json"))
        for json_file in json_files:
            if self._is_synthetic_json(json_file):
                violations.append(f"JSON file appears to be synthetic: {json_file}")
        
        # å®Ÿæ¸¬ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œè¨¼
        if not self.real_data_dir.exists():
            violations.append("Real data directory 'runs/real' does not exist")
        else:
            real_data_valid = self._validate_real_data_structure()
            if not real_data_valid:
                violations.append("Real data directory structure is invalid")
        
        is_valid = len(violations) == 0
        
        if is_valid:
            print("âœ… No synthetic data detected - all data is real measurement")
        else:
            print(f"âŒ Found {len(violations)} synthetic data violations:")
            for violation in violations:
                print(f"   - {violation}")
        
        return is_valid, violations
    
    def _contains_synthetic_data_code(self, file_path: Path) -> bool:
        """Pythonãƒ•ã‚¡ã‚¤ãƒ«ãŒåˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã‚’å«ã‚€ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            with file_path.open('r', encoding='utf-8') as f:
                content = f.read()
            
            # çµ±è¨ˆåˆ†æç”¨ã®åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ã‚’æ¤œå‡º
            synthetic_patterns = [
                "simulate_experiment",
                "generate_synthetic_data", 
                "fake_data",
                "mock_data",
                "synthetic_scores",
                "simulate_baseline",
                "simulate_elm_only",
                "simulate_llm_teacher",
                "simulate_random_teacher",
                "simulate_rule_teacher"
            ]
            
            # çµ±è¨ˆåˆ†æç”¨ã®åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ã¿ã‚’æ¤œå‡º
            for pattern in synthetic_patterns:
                if pattern in content:
                    # æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ è‡ªä½“ã¯é™¤å¤–
                    if file_path.name in ["validate_real_data.py", "logger.py"]:
                        continue
                    lines = content.split('\n')
                    for line in lines:
                        stripped = line.strip()
                        if pattern in stripped and not stripped.startswith('#') and not stripped.startswith('"""') and not stripped.startswith("'''"):
                            return True
            
            # çµ±è¨ˆåˆ†æã§ã®å¤§é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
            if "for episode in range(" in content and "np.random" in content:
                # å¤§é‡ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç”Ÿæˆï¼ˆ50ä»¥ä¸Šï¼‰ã¯åˆæˆãƒ‡ãƒ¼ã‚¿ã®å¯èƒ½æ€§
                import re
                range_matches = re.findall(r'range\((\d+)\)', content)
                for match in range_matches:
                    if int(match) >= 50:  # 50ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä»¥ä¸Šã¯åˆæˆãƒ‡ãƒ¼ã‚¿ã®å¯èƒ½æ€§
                        return True
            
            return False
            
        except Exception:
            return False
    
    def _is_synthetic_json(self, file_path: Path) -> bool:
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒåˆæˆãƒ‡ãƒ¼ã‚¿ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            with file_path.open('r', encoding='utf-8') as f:
                data = json.load(f)
            
            # åˆæˆãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ã‚’æ¤œå‡º
            if isinstance(data, dict):
                # å¤§é‡ã®å‡ä¸€ãªãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³
                if 'experiment_data' in data:
                    exp_data = data['experiment_data']
                    if isinstance(exp_data, dict):
                        for condition, episodes in exp_data.items():
                            if isinstance(episodes, list) and len(episodes) > 50:
                                # 50ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä»¥ä¸Šã¯åˆæˆãƒ‡ãƒ¼ã‚¿ã®å¯èƒ½æ€§ãŒé«˜ã„
                                return True
                
                # çµ±è¨ˆçµæœã®ç•°å¸¸ãªãƒ‘ã‚¿ãƒ¼ãƒ³
                if 'descriptive_statistics' in data:
                    stats = data['descriptive_statistics']
                    if isinstance(stats, dict):
                        for condition, stat in stats.items():
                            if isinstance(stat, dict) and 'mean' in stat:
                                # ç•°å¸¸ã«æ•´ã£ãŸæ•°å€¤ã¯åˆæˆãƒ‡ãƒ¼ã‚¿ã®å¯èƒ½æ€§
                                mean = stat.get('mean', 0)
                                if isinstance(mean, (int, float)) and mean == int(mean):
                                    return True
            
            return False
            
        except Exception:
            return False
    
    def _validate_real_data_structure(self) -> bool:
        """å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ§‹é€ ã‚’æ¤œè¨¼"""
        if not self.real_data_dir.exists():
            return False
        
        # å®Ÿæ¸¬ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        has_real_logs = False
        
        for experiment_dir in self.real_data_dir.iterdir():
            if experiment_dir.is_dir():
                # CSV/JSONãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
                csv_files = list(experiment_dir.glob("**/*.csv"))
                json_files = list(experiment_dir.glob("**/*.json"))
                
                if csv_files or json_files:
                    has_real_logs = True
                    break
        
        return has_real_logs
    
    def generate_data_integrity_report(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        print("ğŸ“Š Generating data integrity report...")
        
        is_valid, violations = self.validate_no_synthetic_data()
        
        # å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
        real_data_stats = self._collect_real_data_stats()
        
        # è¨­å®šãƒãƒƒã‚·ãƒ¥ã®æ¤œè¨¼
        config_hashes = self._validate_config_hashes()
        
        report = {
            "validation_timestamp": pd.Timestamp.now().isoformat(),
            "synthetic_data_validation": {
                "is_valid": is_valid,
                "violations": violations,
                "total_violations": len(violations)
            },
            "real_data_statistics": real_data_stats,
            "configuration_hashes": config_hashes,
            "data_quality_score": self._calculate_quality_score(is_valid, real_data_stats, config_hashes)
        }
        
        return report
    
    def _collect_real_data_stats(self) -> Dict[str, Any]:
        """å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã‚’åé›†"""
        stats = {
            "total_experiments": 0,
            "total_episodes": 0,
            "total_steps": 0,
            "conditions": [],
            "seeds_used": [],
            "date_range": {"earliest": None, "latest": None}
        }
        
        if not self.real_data_dir.exists():
            return stats
        
        for experiment_dir in self.real_data_dir.iterdir():
            if experiment_dir.is_dir():
                stats["total_experiments"] += 1
                
                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çµ±è¨ˆåé›†
                csv_files = list(experiment_dir.glob("**/*.csv"))
                for csv_file in csv_files:
                    try:
                        df = pd.read_csv(csv_file)
                        stats["total_steps"] += len(df)
                        
                        if 'episode' in df.columns:
                            stats["total_episodes"] += df['episode'].nunique()
                        
                        if 'condition' in df.columns:
                            conditions = df['condition'].unique().tolist()
                            stats["conditions"].extend(conditions)
                        
                        if 'seed' in df.columns:
                            seeds = df['seed'].unique().tolist()
                            stats["seeds_used"].extend(seeds)
                            
                    except Exception:
                        continue
        
        # é‡è¤‡é™¤å»
        stats["conditions"] = list(set(stats["conditions"]))
        stats["seeds_used"] = list(set(stats["seeds_used"]))
        
        return stats
    
    def _validate_config_hashes(self) -> Dict[str, Any]:
        """è¨­å®šãƒãƒƒã‚·ãƒ¥ã®æ¤œè¨¼"""
        hashes = {
            "total_configs": 0,
            "unique_hashes": [],
            "hash_consistency": True
        }
        
        if not self.real_data_dir.exists():
            return hashes
        
        for config_file in self.real_data_dir.glob("**/config_*.json"):
            try:
                with config_file.open('r') as f:
                    config = json.load(f)
                
                if 'config_hash' in config:
                    hash_value = config['config_hash']
                    hashes["unique_hashes"].append(hash_value)
                    hashes["total_configs"] += 1
                    
            except Exception:
                continue
        
        # ãƒãƒƒã‚·ãƒ¥ã®ä¸€æ„æ€§ç¢ºèª
        unique_count = len(set(hashes["unique_hashes"]))
        hashes["unique_count"] = unique_count
        hashes["hash_consistency"] = unique_count == hashes["total_configs"]
        
        return hashes
    
    def _calculate_quality_score(self, is_valid: bool, real_data_stats: Dict, config_hashes: Dict) -> float:
        """ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0-100ï¼‰"""
        score = 0.0
        
        # åˆæˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆ40ç‚¹ï¼‰
        if is_valid:
            score += 40.0
        
        # å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ï¼ˆ30ç‚¹ï¼‰
        if real_data_stats["total_experiments"] > 0:
            score += 30.0
        
        # è¨­å®šãƒãƒƒã‚·ãƒ¥ã®æ•´åˆæ€§ï¼ˆ20ç‚¹ï¼‰
        if config_hashes["hash_consistency"]:
            score += 20.0
        
        # ãƒ‡ãƒ¼ã‚¿é‡ã®å……å®Ÿåº¦ï¼ˆ10ç‚¹ï¼‰
        if real_data_stats["total_steps"] > 1000:
            score += 10.0
        elif real_data_stats["total_steps"] > 100:
            score += 5.0
        
        return score
    
    def save_validation_report(self, output_path: str = "data_validation_report.json"):
        """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜"""
        report = self.generate_data_integrity_report()
        
        output_file = self.project_dir / output_path
        with output_file.open('w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ Validation report saved: {output_file}")
        print(f"ğŸ† Data quality score: {report['data_quality_score']:.1f}/100")
        
        return report


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    validator = RealDataValidator()
    
    print("ğŸ”¬ Starting real data validation...")
    print("=" * 60)
    
    # æ¤œè¨¼å®Ÿè¡Œ
    is_valid, violations = validator.validate_no_synthetic_data()
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»ä¿å­˜
    report = validator.save_validation_report()
    
    print("=" * 60)
    
    if is_valid and report['data_quality_score'] >= 80:
        print("âœ… VALIDATION PASSED: System uses real data only")
        print("ğŸ”¬ Scientific rigor confirmed")
    else:
        print("âŒ VALIDATION FAILED: Issues detected")
        print("âš ï¸  Please address violations before proceeding")
        
        if violations:
            print("\nğŸ”§ Recommended actions:")
            print("1. Move synthetic data files to sim/deprecated/")
            print("2. Ensure all analysis uses runs/real/ data only")
            print("3. Verify configuration hashes are consistent")
            print("4. Run experiments to generate real measurement data")


if __name__ == "__main__":
    main()
