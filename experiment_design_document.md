# Tower Defense ELM Learning Efficiency Experiment Design

## 実験概要

**目的**: 未訓練ELM（Extreme Learning Machine）におけるLLMガイダンスの学習効率向上効果を実際のゲーム環境で検証する

**仮説**: LLMガイダンスがあることで、ELMはより効率的に学習し、同じ性能レベルに短時間で到達する

## 実験設計

### 1. 実験条件

#### 1.1 被験体システム
- **ELMのみ条件**: 未訓練ELM（ランダム初期パラメータ、random_state=42）
- **ELM+LLM条件**: 未訓練ELM（ランダム初期パラメータ、random_state=123）+ OpenAI GPT-4o-mini ガイダンス

#### 1.2 ゲーム環境
- **プラットフォーム**: ブラウザベースのタワーディフェンスゲーム
- **ゲーム設定**:
  - タワーコスト: $50
  - タワー攻撃力: 60
  - タワー射程: 150px
  - 敵体力: 80
  - 敵移動速度: 0.7
  - 敵撃破報酬: $30
  - 攻撃間隔: 500ms

#### 1.3 実験パラメータ
- **試行回数**: 各条件10回（合計20回）
- **試行時間**: 1回あたり2分間（120秒）
- **自動化間隔**: 2秒ごとにELM判断実行
- **LLMガイダンス頻度**: 10%の確率で取得

### 2. 測定指標

#### 2.1 基本性能指標
- **最終スコア**: 試行終了時の総スコア
- **生存時間**: ヘルスが0になるまでの時間
- **タワー配置数**: 配置されたタワーの総数
- **敵撃破数**: 撃破した敵の総数

#### 2.2 学習効率指標
- **学習時間**: 実験開始からの経過時間
- **学習率**: 分あたりのスコア改善率（点/分）
- **効率スコア**: 時間あたりの性能向上（点/秒）
- **学習更新回数**: ELMの重み更新回数
- **LLMガイダンス使用回数**: LLMからの指導を受けた回数

#### 2.3 閾値到達時間
以下のスコア閾値に到達するまでの時間を測定：
- 50点到達時間
- 100点到達時間
- 200点到達時間
- 300点到達時間
- 500点到達時間

### 3. 実験手順

#### 3.1 事前準備
1. 実験システムの起動確認
2. OpenAI API接続確認
3. ゲーム環境の動作確認
4. データ収集システムの確認

#### 3.2 実験実行
1. **ELMのみ条件（10回）**:
   - モードを「ELM Only」に設定
   - 各試行で未訓練ELMをリセット
   - 2分間の自動プレイを実行
   - 学習効率データを記録

2. **ELM+LLM条件（10回）**:
   - モードを「ELM + LLM Guidance」に設定
   - 各試行で未訓練ELMをリセット
   - LLMガイダンスを有効化
   - 2分間の自動プレイを実行
   - 学習効率データを記録

#### 3.3 データ収集
各試行で以下のデータを自動収集：
```json
{
  "mode": "elm_only | elm_llm",
  "trial": 1-10,
  "score": "最終スコア",
  "health": "残りヘルス",
  "towers": "タワー数",
  "duration": "試行時間(ms)",
  "timestamp": "実行時刻",
  "learning_metrics": {
    "total_time": "学習時間(秒)",
    "learning_rate": "学習率(点/分)",
    "efficiency_score": "効率スコア(点/秒)",
    "total_learning_updates": "学習更新回数",
    "llm_guidance_count": "LLMガイダンス回数",
    "threshold_times": {
      "50": "50点到達時間",
      "100": "100点到達時間",
      "200": "200点到達時間",
      "300": "300点到達時間",
      "500": "500点到達時間"
    },
    "performance_history": "時系列性能データ"
  }
}
```

### 4. 統制条件

#### 4.1 環境統制
- 同一のハードウェア環境
- 同一のブラウザ環境
- 同一のネットワーク条件
- 同一のゲーム物理エンジン

#### 4.2 ランダム性統制
- ELMの初期パラメータは固定シード使用
- 敵の生成パターンは疑似ランダム
- LLMガイダンスの取得タイミングは確率的

#### 4.3 学習条件統制
- 両条件とも未訓練状態から開始
- 同一の学習アルゴリズム使用
- 同一の経験バッファサイズ

### 5. 期待される結果

#### 5.1 仮説検証項目
1. **学習効率の向上**: ELM+LLM条件でより高い学習率を示す
2. **閾値到達時間の短縮**: ELM+LLM条件でより早く性能閾値に到達
3. **最終性能の向上**: ELM+LLM条件でより高い最終スコアを達成
4. **学習安定性の向上**: ELM+LLM条件でより安定した学習曲線を示す

#### 5.2 統計的検定
- **t検定**: 両条件間の平均性能差の検定
- **Mann-Whitney U検定**: 非パラメトリック検定による確認
- **効果量**: Cohen's dによる実用的意義の評価
- **信頼区間**: 95%信頼区間による推定精度の評価

### 6. 実験の妥当性

#### 6.1 内的妥当性
- ランダム化による交絡要因の統制
- 同一環境での比較による系統誤差の排除
- 自動化による測定誤差の最小化

#### 6.2 外的妥当性
- 実際のゲーム環境での測定
- 現実的な時間制約下での評価
- 実用的なタスクでの検証

#### 6.3 構成概念妥当性
- 学習効率の多面的測定
- 時系列データによる学習過程の追跡
- 複数の性能指標による総合評価

### 7. 実験実施上の注意点

#### 7.1 技術的注意点
- OpenAI APIの利用制限に注意
- ブラウザの安定性確保
- データの自動保存確認

#### 7.2 データ品質管理
- 異常値の検出と処理
- 欠損データの確認
- 実験条件の一貫性確認

#### 7.3 倫理的配慮
- APIの適切な使用
- データの適切な管理
- 結果の客観的報告

## 実験スケジュール

1. **準備フェーズ** (30分)
   - システム起動と動作確認
   - API接続確認
   - 実験条件設定

2. **ELMのみ条件実行** (25分)
   - 10回の試行実行
   - データ収集と確認

3. **ELM+LLM条件実行** (25分)
   - 10回の試行実行
   - データ収集と確認

4. **データ分析** (30分)
   - 統計分析実行
   - 結果の可視化
   - レポート作成

**総実験時間**: 約110分

## 成功基準

実験は以下の条件を満たした場合に成功とみなす：

1. **データ完全性**: 全20回の試行でデータが正常に収集される
2. **統計的有意性**: 主要指標で統計的有意差が検出される
3. **効果の方向性**: ELM+LLM条件が仮説通りの改善を示す
4. **再現性**: 結果が理論的に説明可能である

この実験設計により、LLMガイダンスによる学習効率向上効果を科学的に検証する。
